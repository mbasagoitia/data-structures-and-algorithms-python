# Amortized Analysis

Technique for analyzing the cost of operations on data structures

- push/pop = 1
- popAll = as many elements as you remove

## Accounting Method

Think of computation time as money...

- Suppose we have n combinations of stack operations which can be push, pop, or popAll. What is the worst-case complexity?
    - Realize that the complexity of an expensive operation like popAll is related to previous push operations
    - Think of push being a "prepaid" operation; say you paid 2 time units for each push operation so that its later pop/popAll operations are "free"
    - In the worst case, every operation would be push, so the worst-case complexity would be O(2n)
    - Following that, the amortized cost of every operation would be f(n) / n = 2 (constant)
    - Any combination of these operations is in the worst case O(n)

## Another Example: Binary Counter

To summarize the algorithm to increment a binary counter:

- Travelling from right to left, as long as you encounter 1 bits, convert to 0
- When you reach the first (rightmost) 0, convert it to a 1 and STOP

We may assume that the worst-case complexity is O(k * n) (number of increments * number of bits)

Amortized analysis tells us that once we encounter the "worst case" operation of n bits, it cannot occur over and over since all of the 1s will be reset to 0s.

In other words, the worst-case for any single operation cannot be extrapolated to your set of n operations.

### Accounting Method for Binary Counter

- Pay $2 for each change of counter from 0 to 1; $1 for the operation, and $1 paid forward to support future change from 1 to 0

- So, for each operation, there are k changes from 1 to 0 (1 incurred - 1 prepaid = 0)
- 1 change from 0 to 1 (1 incurred + 1 prepaid = 2)
- Total amortized cost = 2 operations
- Amortized cost of k increments = **2k**

## Dynamic Arrays

Remember, when a dynamic array reaches the limit of its allocated space, it needs to reallocate a new array twice as large and copy the elements of the old array over.

Initially, we may think:

Cost of n insert operations:
- Worst-case: each insertion can cause resizing
- Cost of resizing is current size of array
- Worst-case size of array is n
- Worst-case cost of insertions is O(n^2)

This is a huge overestimation!

### Amortized analysis of dynamic array insertion

- Pay $3 for each insertion
    - $1 for actual cost of insertion
    - $2 for future costs associated with resizing ($1 for copying itself, $1 for copying another element in the first half of the array since the new allocated size is doubled)
    - In this way, the latest n/2 inserts are paying for the earliest n/2 inserts which already paid when they were copied over

- In this way, the cost of resizing is already paid for; the cost of an insertion remains $3 even if resizing occurs.

Therefore, the amortized cost of n insertions is 3n

## Potential Functions

Idea borrowed from physics

Mathematically-rigorous alternative method to the accounting method to perform amortized analysis

Basic idea: Associate a potential function with the data structure

Think of operations on your data structures creating new instances of the data structure (Di -> Di + 1) with computation cost c.

Amortized cost = potential(D sub(i + 1)) - potential(Dsub(i)) + csub(i)
    - A.C. = change in the potential plus the cost of the operation

Total amortized cost of n operations: actual cost + total change in potential from initial data structure to final data structure

For any sequence of n operations, the amortized cost places an upper bound on the actual costs if we can guarantee that the potential of later data structure instances is greater than or equal to the starting potential. Potential should always remain above the starting value, but it can decrease. Think of the rolling ball... it can go up the hill, but can never go lower than the starting point at ground level.
